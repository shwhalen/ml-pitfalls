{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance Inflation on Graph-Structured Data\n",
    "\n",
    "From biology to telecommunications, many real world networks can be described by the process of preferential attachment where well-connected (high *degree*) nodes are more likely to form new edges. In terms of degrees, \"the rich get richer\".\n",
    "\n",
    "A diverse set of prediction problems in biology involve interactions between elements of a single set (e.g., proteins), or between elements of two disjoint sets (e.g. protein-ligand, drug-target, enhancer-promoter).  These sets and their interactions can be represented by a graph or network structure, with nodes representing elements of a set and edges representing their interactions.\n",
    "\n",
    "However, edges that share nodes create non-independent examples when graphs are encoded into a tabular format for machine learning.  This notebook illustrates this encoding process and how the resulting dependent examples can inflate cross-validation performance due to information leakage.  This leakage scales with the number of edges in the graph and affects both linear and non-linear classifiers, though the latter scale more quickly.\n",
    "\n",
    "The amount of leakage that occurs depends on the dataset, but has impacted multiple independent areas of genomics discussed in our review.  We demonstrate the generality of this pitfall for any graph-structured dataset where non-graph-aware machine learning algorithms are applied.  The pitfall is not specific to graphs formed by preferential attachment, though the presence of high degree nodes in such networks is helpful for demonstrating leakage.\n",
    "\n",
    "[NetworkX](https://networkx.github.io) is used for the creation and manipulation of graphs.  Nodes are represented by integer identifiers and edges as integer tuples containing source and destination node identifiers.  Nodes and edges may have optional *attributes* which store data as key/value pairs.  No further knowledge of NetworkX should be required to understand the following notebook.\n",
    "\n",
    "#### - Sean Whalen, Gladstone Institutes, Pollard Lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "from itertools import chain, product\n",
    "from joblib import Parallel, delayed\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GroupKFold, StratifiedKFold, cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin by generating a sequence of numbers drawn from a power law distribution which often captures the long-tailed degree distribution of networks formed by preferential attachment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degree_sequence = nx.utils.powerlaw_sequence(8)\n",
    "print(degree_sequence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converted to integers, this degree sequence specifies how many edges each node has.  We will use this sequence to inform the generation of a random graph.\n",
    "\n",
    "A bipartite graph has nodes consisting of two disjoint sets.  We create a random bipartite graph by specifying the degree sequence of the first set (the length of this sequence specifies the number of nodes), the probability of creating a new node in the second set versus creating a new edge via preferential attachment, and a seed for the random number generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = nx.bipartite.preferential_attachment_graph(\n",
    "    np.asarray(degree_sequence, int),\n",
    "    p = 0.6,\n",
    "    seed = 0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While creating the graph, this function adds a node *attribute* named `bipartite` that is set to 0 or 1 if the node is in set 1 or 2, respectively.\n",
    "\n",
    "We can view this graph by determining which nodes are in set 1 and drawing the graph using a bipartite layout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set1_nodes = {node for node, data in graph.nodes(data = True) if data['bipartite'] == 0}\n",
    "layout = nx.bipartite_layout(graph, set1_nodes)\n",
    "nx.draw(graph, layout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that sets 1 and 2 can have different numbers of nodes, and that nodes can have multiple edges.\n",
    "\n",
    "A common machine learning task in genomics is link (edge) prediction, where the algorithm learns properties of connected node pairs in one graph to predict links between node pairs in another. Examples include predicting novel protein interactions, or predicting chromatin interactions between enhancers and promoters.  Most machine learning algorithms cannot handle graphs directly, and instead operate on a matrix of features where rows are examples and columns are features describing those examples. This is a *tabular* format, and so we refer to the tabular representation of a graph as its *tabular encoding*.\n",
    "\n",
    "In a tabular encoding, each node is described by a feature vector and edges (node pairs) are thus the concatenation of two node feature vectors. To create labels for supervised learning, positive examples are node pairs with an edge in the graph, and negative examples are node pairs without edges.  This process is illustrated in a toy graph with disjoint node sets *A* and *B* that could (for example) represent proteins and ligands, drugs and targets, or enhancers and promoters.\n",
    "\n",
    "![](../images/leakage.png)\n",
    "\n",
    "Evaluating a model trained on a tabular encoding of a graph using k-fold cross-validation can cause potentially severe performance inflation. This is because node pairs are dependent (violating the Independent-and-Identically-Distributed assumption of most statistical models), and k-fold cross-validation is unaware of these dependencies. In the above example, the edge *A1-B1* is in the training set, and *A1-B2* is in the test set. The model will observe the features of node *A1* during training, and so may be more likely to predict a link between *A1* and *B2* independent of *B2*'s features. In other words, the model may end up learning the degree distribution of specific nodes, rather than properties of the edge that will generalize to unobserved data.\n",
    "\n",
    "The function below creates a random bipartite graph for a given set of parameters, creates a tabular encoding of that graph, and evaluates the performance of baseline (random), logistic regression, and random forest classifiers using both non-blocking and blocking cross-validation.  Importantly, nodes are assigned random length-3 feature vectors: classifiers should not have above random performance.\n",
    "\n",
    "For simplicity, blocking cross-validation is passed the source node of each edge so that all edges with the same source node will be either in the training set or the test set.  This will reduce leakage but not eliminate it; in practice, disjoint sets of edges that share no nodes should be identified.  For many genomics problems this is possible by holding out entire chromosomes as test sets.  However, it may not be possible to completely eliminate information leakage for more complex networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_performance(total_set1_nodes, bottom_node_probability, seed):\n",
    "    # initialize random number generators\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # create a power law degree distribution,\n",
    "    # then create a random bipartite graph with preferentially attached edges\n",
    "    degree_sequence = nx.utils.powerlaw_sequence(total_set1_nodes)\n",
    "    graph = nx.bipartite.preferential_attachment_graph(\n",
    "        np.asarray(degree_sequence, int),\n",
    "        p = bottom_node_probability,\n",
    "        seed = seed\n",
    "    )\n",
    "\n",
    "    # compute nodes in sets 1 and 2\n",
    "    set1_nodes = {node for node, data in graph.nodes(data = True) if data['bipartite'] == 0}\n",
    "    set2_nodes = graph.nodes - set1_nodes\n",
    "\n",
    "    # compute missing edges as the set of possible edges minus the set of existing edges\n",
    "    possible_edges = set(product(set1_nodes, set2_nodes))\n",
    "    actual_edges = set(graph.edges())\n",
    "    missing_edges = possible_edges - actual_edges\n",
    "\n",
    "    # subsample missing edges for use as negative examples\n",
    "    missing_edges_subset = random.sample(\n",
    "        list(missing_edges),\n",
    "        graph.number_of_edges() * negatives_per_positive\n",
    "    )\n",
    "\n",
    "    # create random length-3 feature vector for each node in graph\n",
    "    for node in graph:\n",
    "        graph.nodes[node]['features'] = np.random.normal(0, 1, 3)\n",
    "\n",
    "    # featurize all edges (node pairs) for actual and missing edges\n",
    "    features = [\n",
    "        np.append(graph.nodes[src]['features'], graph.nodes[dst]['features'])\n",
    "        for src, dst in list(actual_edges) + list(missing_edges_subset)\n",
    "    ]\n",
    "    \n",
    "    # compute first node of each edge so blocking cv can respect dependencies\n",
    "    features_set1_nodes = [src for src, dst in list(actual_edges) + list(missing_edges_subset)]\n",
    "    \n",
    "    # supervised labels: 1 for positive examples, 0 for negative examples\n",
    "    labels = np.array([1] * len(actual_edges) + [0] * len(missing_edges_subset))\n",
    "\n",
    "    # 5-fold cross-validation with shuffling, ignores node dependencies\n",
    "    cv = StratifiedKFold(\n",
    "        n_splits = 5,\n",
    "        shuffle = True,\n",
    "        random_state = seed\n",
    "    )\n",
    "    \n",
    "    # blocking cross-validation, respects node dependencies\n",
    "    blocking_cv = GroupKFold(\n",
    "        n_splits = 5\n",
    "    )\n",
    "    \n",
    "    # compute percent of positive classes in blocking cv test sets, for potential plotting\n",
    "    class_balances = [\n",
    "        labels[test_indices].mean()\n",
    "        for train_indices, test_indices in blocking_cv.split(features, labels, features_set1_nodes)\n",
    "    ]\n",
    "\n",
    "    # classifier generating random predictions for baseline performance estimate\n",
    "    baseline_estimator = DummyClassifier(strategy = 'uniform')\n",
    "    \n",
    "    # linear classifier\n",
    "    lm_estimator = LogisticRegression()\n",
    "    \n",
    "    # ensemble classifier\n",
    "    rf_estimator = RandomForestClassifier(n_estimators = 50, random_state = seed)\n",
    "    \n",
    "    # evaluate all models using blocking and non-blocking cv\n",
    "    estimators = [('baseline', baseline_estimator), ('lm', lm_estimator), ('rf', rf_estimator)]\n",
    "    all_scores = []\n",
    "\n",
    "    for model_type, estimator in estimators:\n",
    "        scores = cross_val_score(\n",
    "            estimator,\n",
    "            features,\n",
    "            labels,\n",
    "            cv = cv,\n",
    "            scoring = scoring\n",
    "        )\n",
    "\n",
    "        blocked_scores = cross_val_score(\n",
    "            estimator,\n",
    "            features,\n",
    "            labels,\n",
    "            cv = blocking_cv,\n",
    "            groups = features_set1_nodes,\n",
    "            scoring = scoring\n",
    "        )\n",
    "\n",
    "        all_scores.append([\n",
    "            total_set1_nodes,\n",
    "            graph.number_of_nodes(),\n",
    "            len(actual_edges),\n",
    "            bottom_node_probability,\n",
    "            seed,\n",
    "            model_type,\n",
    "            'unblocked',\n",
    "            np.median(class_balances),\n",
    "            np.median(scores)\n",
    "        ])\n",
    "\n",
    "        all_scores.append([\n",
    "            total_set1_nodes,\n",
    "            graph.number_of_nodes(),\n",
    "            len(actual_edges),\n",
    "            bottom_node_probability,\n",
    "            seed,\n",
    "            model_type,\n",
    "            'blocked',\n",
    "            np.median(class_balances),\n",
    "            np.median(blocked_scores)\n",
    "        ])\n",
    "\n",
    "    return all_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now define a scoring function (`average_precision` is area under the precision-recall curve), the number of missing links to featurize per existing link, and a set of parameters for generating random bipartite graphs.  For speed we recommend using the defaults below, though the results have been observed to hold for graphs of many sizes across thousands of initial conditions (seeds)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = 'average_precision'\n",
    "negatives_per_positive = 5\n",
    "\n",
    "params = product(\n",
    "    [100], # number of nodes\n",
    "    np.arange(0.3, 0.75, 0.05), # probability of new node vs new preferentially attached edge\n",
    "    range(5) # seeds\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we generate random graphs for all parameters in parallel, using all available CPU cores.  This may take a while on low core system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = Parallel(-1)(\n",
    "    delayed(get_performance)(*_)\n",
    "    for _ in params\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For plotting, we convert these results to a Pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = pd.DataFrame(\n",
    "    chain.from_iterable(scores),\n",
    "    columns = [\n",
    "        'total_set1_nodes',\n",
    "        'total_nodes',\n",
    "        'total_edges',\n",
    "        'bottom_node_probability',\n",
    "        'seed',\n",
    "        'model_type',\n",
    "        'cv_type',\n",
    "        'median_positives_percent',\n",
    "        'score'\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each combination of model and cross-validation type, we plot a linear model fit to performance as a function of the total number of graph edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.set_style('white')\n",
    "\n",
    "scores['model_and_cv_type'] = scores['model_type'] + '.' + scores['cv_type']\n",
    "\n",
    "sns.lmplot(\n",
    "    x = 'total_edges',\n",
    "    y = 'score',\n",
    "    hue = 'model_and_cv_type',\n",
    "    palette = 'Paired',\n",
    "    data = scores\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unblocked cross-validation performance of both models increases with the number of edges, with the random forest more quickly exploiting leakage due to nodes shared by edges in the training and test sets.  When blocking cross-validation is used, both models return to baseline performance.\n",
    "\n",
    "The amount of edges crossing the train-test divide is particularly problematic in a graph formed via preferential attachment, and so we emphasize the amount of leakage is dependent on the properties of a particular graph-structured dataset.  However, real-world examples in genomics have demonstrated extreme performance inflation where non-blocking cross-validation estimated excellent predictive performance for models that were later shown to capture other properties like degree distribution.  We hope this notebook increases awareness of this pitfall and its prevention."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
